:mod:`gpflux.layers.bayesian_dense_layer`
=========================================

.. py:module:: gpflux.layers.bayesian_dense_layer

.. autoapi-nested-parse::

   A Bayesian Dense Keras Layer



Module Contents
---------------

.. class:: BayesianDenseLayer(input_dim: int, output_dim: int, num_data: int, w_mu: Optional[np.ndarray] = None, w_sqrt: Optional[np.ndarray] = None, activation: Optional[Callable] = None, is_mean_field: bool = True, temperature: float = 0.0001, returns_samples: bool = True)


   Bases: :class:`gpflux.layers.trackable_layer.TrackableLayer`

   A Bayesian dense layer for variational Bayesian neural networks

   A Bayesian dense layer for variational Bayesian neural nets. This layer holds the
   weight mean and sqrt as well as the temperature for cooling (or heating) the posterior.

   :param input_dim: The layer's input dimension (excluding bias)
   :param output_dim: The layer's output dimension
   :param num_data: number of data points
   :param w_mu: Initial value of the variational mean (weights + bias)
   :param w_sqrt: Initial value of the variational Cholesky (covering weights + bias)
   :param activation: The type of activation function (None is linear)
   :param is_mean_field: Determines mean field approximation of the weight posterior
   :param temperature: For cooling or heating the posterior
   :param returns_samples: If True, return samples on calling the layer,
        Else return mean and variance

   .. method:: build(self, input_shape: gpflux.types.ShapeType) -> None

      Build the variables necessary on first call


   .. method:: predict_samples(self, inputs: gpflow.base.TensorType, *, num_samples: Optional[int] = None, full_output_cov: bool = False, full_cov: bool = False, whiten: bool = False) -> tensorflow.Tensor

      Make a sample predictions at N test inputs, with input_dim = D, output_dim = Q. Return a
      sample, and the conditional mean and covariance at these points.

      :param inputs: the inputs to predict at. shape [N, D]
      :param num_samples: the number of samples S, to draw.
          shape [S, N, Q] if S is not None else [N, Q].
      :param full_output_cov: assert to False since not supported for now
      :param full_cov: assert to False since not supported for now
      :param whiten: assert to False since not sensible in Bayesian neural nets


   .. method:: call(self, inputs: gpflow.base.TensorType, training: Optional[bool] = False) -> Union[(tf.Tensor, MeanAndVariance)]

      The default behaviour upon calling the BayesianDenseLayer()(X)


   .. method:: prior_kl(self) -> tensorflow.Tensor

      The KL divergence from the variational distribution to the prior
      :return: KL divergence from N(w_mu, w_sqrt) to N(0, I)



